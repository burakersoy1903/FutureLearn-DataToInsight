Week 01 -- 03232018 ------------------------------------------------------------
Introduction -------------------------------------------------------------------
--- 1.1 Course introduction ----------
Chris quote: "Diving into data"
iNZight -- https://www.stat.auckland.ac.nz/~wild/iNZight/index.php
--- 1.2 About this course ----------
You create visual representations of data, usually in the iNZight software.
Discussion about specified topics, such as possible interpretations of statistical data.
Lead educator, Chris Wild, (https://www.stat.auckland.ac.nz/~wild) (@ChrisWild)
Educator, Tracey Meek,
Educator, Mike Forster, (@MikeForster)
Technology mentor, Tom Elliott.(http://tomelliott.co.nz)(inzight_support@auckland.ac.nz)
--- 1.3 How to use FutureLearn ----------
Follow teachers
--- 1.4 Welcome - please introduce yourself ----------
Howdy, y'all! This is Burak Ersoy. I live in Texas, USA; however, I am from Turkey originally. I work as a business clinical analyst at a children's hospital and I hold a MSc. in Computer Science. With that being said, I am not new in data analytics or technology, but I am new in R and medical statistics. I am very excited to see examples with health data and ready to learn new approaches through this Data to Insight challenge. Thank you!
--- 1.5 How do we use data analysis? ----------
So statistics lets us give an air of objectivity rather than just an opinion.
Even hospitals make clever use of data to cut costs and to keep patients moving through the system. We used data analysis to help the heart unit at Auckland City Hospital fix a bottleneck in their system. This bottleneck was causing nearly 30% of elective heart surgeries to be cancelled at the very last minute. And this wasn't just costly for the hospital, but was also very, very stressful for patients and their families. So we built a model of the patient flow through the intensive-care unit. And we fed into this model all kinds of data: the data of the arrival times of patients, the kind of treatment they needed, how long they spent in the unit. And then also staff rosters and the schedules for elective surgery. And then we used this model to simulate all kinds of "what if?" scenarios-- a whole range of them-- to see what the best way would be to reduce cancellations. The hospital then made some changes and the cancellation rate fell from nearly 30% to 10%.
--- 1.6 The place of data analysis in problem solving ----------
Check "Images/ppdac.png"
The PPDAC model: Problem, Plan, Data, Analysis, Conclusions
A knowledge-based solution to the real problem requires better understanding of how some things work.
“whipping it into shape” (data cleaning)
The Problem step is about trying to turn these vague feelings into much more precise goals, some very specific questions that should be able to be answered using data.
The formation of conclusions typically involves the analyst and a subject-matter expert (e.g. someone who understands the business) who will “own” the conclusions.
This article has been about purpose-collected data.
Check "Articles/1.6-Statistical Thinking in Empirical Enquiry.pdf" --Original PPDAC model article
--- 1.7 Datasets for Data to Insight ----------
“Garbage in, Garbage out” is a standard catch-phrase in information-technology and it certainly applies to statistical data analysis today.
The main datasets for this course are NHANES and Gapminder.
NHANES: National Health and Nutrition Examination Survey (https://www.cdc.gov/nchs/nhanes/index.htm)
Gapminder: (https://www.gapminder.org/) (https://www.gapminder.org/data/)
Check "Articles/1.7-gapminder-dataset-overview.pdf"
Datasets in csv format (https://www.stat.auckland.ac.nz/~wild/data/FutureLearn/)
Datasets in tab-delimited text format (https://www.stat.auckland.ac.nz/~wild/data/FutureLearn_TabTxt/)
Also available in Datasets folder
--- 1.8 Data visualisation ----------
The Joy of Stats: (https://www.gapminder.org/videos/the-joy-of-stats/)
--- 1.9 Introduction to iNZight and iNZight Lite  ----------
To gain insights into the real world using data you need to produce graphs and summaries using statistical data-analysis software.
--- 1.10 Exercise - Install iNZight ----------
Check "Exercises/1.10-exercise-install-R_17.pdf"
Check "100-InstallTheRPackages.R"
iNZight Lite: (http://lite.docker.stat.auckland.ac.nz/)
iNZight GitHub: (https://github.com/iNZightVIT)
iNZight User Guides: (https://www.stat.auckland.ac.nz/~wild/iNZight/user_guides/)
package ‘rematch’ successfully unpacked and MD5 sums checked
package ‘rlang’ successfully unpacked and MD5 sums checked
package ‘hms’ successfully unpacked and MD5 sums checked
package ‘cellranger’ successfully unpacked and MD5 sums checked
package ‘tidyselect’ successfully unpacked and MD5 sums checked
package ‘objectSignals’ successfully unpacked and MD5 sums checked
package ‘gtools’ successfully unpacked and MD5 sums checked
package ‘memoise’ successfully unpacked and MD5 sums checked
package ‘readr’ successfully unpacked and MD5 sums checked
package ‘readxl’ successfully unpacked and MD5 sums checked
package ‘forcats’ successfully unpacked and MD5 sums checked
package ‘tidyr’ successfully unpacked and MD5 sums checked
package ‘SparseM’ successfully unpacked and MD5 sums checked
package ‘MatrixModels’ successfully unpacked and MD5 sums checked
package ‘FNN’ successfully unpacked and MD5 sums checked
package ‘gridExtra’ successfully unpacked and MD5 sums checked
package ‘XML’ successfully unpacked and MD5 sums checked
package ‘objectProperties’ successfully unpacked and MD5 sums checked
package ‘RGtk2’ successfully unpacked and MD5 sums checked
package ‘gWidgets2’ successfully unpacked and MD5 sums checked
package ‘cairoDevice’ successfully unpacked and MD5 sums checked
package ‘gdata’ successfully unpacked and MD5 sums checked
package ‘gWidgets2RGtk2’ successfully unpacked and MD5 sums checked
package ‘s20x’ successfully unpacked and MD5 sums checked
package ‘survey’ successfully unpacked and MD5 sums checked
package ‘quantreg’ successfully unpacked and MD5 sums checked
package ‘hexbin’ successfully unpacked and MD5 sums checked
package ‘hextri’ successfully unpacked and MD5 sums checked
package ‘viridis’ successfully unpacked and MD5 sums checked
package ‘gridSVG’ successfully unpacked and MD5 sums checked
--- 1.11 Using iNZight Lite ----------
iNZight Lite is a web-application that runs over the internet and does not need to be installed. It will run on tablets. The user interface for iNZight Lite is rather different from that for iNZight.
--- 1.12 Data organisation ----------
[Comments] I guess in databases, entities are represented in a form of tables during implementation as you said but during design they are referred to as entities in the Entity-Relationship Diagram or Objects if you are using Object-Oriented approach.
Rows and Cells vs. Entities vs Variables (statistical term)
Column header
Data Organisation Format: Rectangular data
Gaps in the data
Missing Value: NULL or NA in iNZight
Different programmes have different default missing-value code conventions.
Numeric Variables vs Categorical Variables (defining groups)
--- 1.13 Week 1 glossary ----------
Check "Articles/1.13-data-to-inzight-glossary.pdf"
Categorical variable, Entities, Frequency, Missing value code, Missing value, Numeric variable, Rectangular data, Variable
--- 1.14 Using your own data ----------
Some general data preparation rules (10 items)
10. Remove units from data, e.g. 5 years/5 yrs/5yr should all be just 5 and $10 is just 10
--- 1.15 Exercise - Load data into iNZight ----------
Check "Exercises/1.15-exercise-import-data-into-R_17.pdf"
Check "100-InstallTheRPackages.R"
--- 1.16 Quiz - Data Organisation ----------
Question 1: We arrange our data in a rectangular format where the entities (or individuals) data is being recorded for correspond to the rowsand the variables (or properties being recorded for those entities) correspond to the columns.
Question 2: We collect and analyse data so we can get insight into a problem of interest, make informed decisions rather than guess, and understand what could happen.
Question 3: The missing value in the red dotted circle should be recorded as a 0 or a space. This statement is FALSE – We should represent a missing value using a special code (e.g. NA for iNZight) or the cell should be entirely empty.
Question 4: AgeDecade is a numeric variable. This statement is FALSE – AgeDecade is a categorical variable because age has been divided up into age groups.
--- 1.17 Weekly Reflections ----------
Nice comments! :D
First week done!


Week 02 -- 03242018 ------------------------------------------------------------
STATS BOOT CAMP ----------------------------------------------------------------
--- 2.1 Introduction ----------
NHANES (in-hayns) survey data
We'll look at variables like Education, Marital Status, and Body Mass Index.
--- 2.2 Categorical variables ----------
Whenever I get a new data set, I try to familiarise myself with what I've got before I do any real analysis. I look for things that might surprise me and might indicate errors in the data. One of the first things I do is to look at each variable in turn.
Numeric variables are those we can think of as measurements, like Age and Weight here. Categorical variables, like Gender, Age Decade, Race3, Education, and Marital Status give us group membership labels.
A categorical variable like Marital Status divides our people up into categories or groups.
In 2011, NHANES changed their race categories to separate out Asian. It had previously been included in "Other". The name of the new variable is Race3.
Pies and stacked bars have the advantages of conveying the sense of being parts of a whole. However, they're not good for discovery because they're not good at letting you see changes and differences. And spotting changes is the lifeblood of discovery.
We get useful impressions of what the data are saying much more quickly from the graph than from a table of numbers. We look first at the graph to get an impression of what's happening, and then consult the table if we want more accuracy.
--- 2.3 Week 2 glossary ----------
Check "Articles/1.13-data-to-inzight-glossary.pdf"
Alpha-numeric, Background Variability, Bar chart, Bimodal, Box Plot, Centre, Dot plot, Frequency, Histogram, Interquartile range (IQR), Lower quartile, Mean, Median, Multiplicative, Nominal variable, Oddities, Ordinal variable, Outlier(s), Overlap, Pie chart, Quartiles, Relative Frequency, Shape, Skewed, Spread, Stacked bar chart, Subset, Symmetrical, Upper quartile, Variability
--- 2.4 Ordering categories ----------
If the categories have a natural ordering, the variable is said to be ordinal.
If there's no natural ordering, the variable is said to be nominal.
If there's no particular reason for setting categories in some other order, ordering them by height order is usually the most informative. We call this ordering by frequency.
Frequency is just another name for a count. 
o wrap up, we have the following ways of ordering. Alphabetic order helps us to locate a particular item in a list just as we do with a name in a phone book. Frequency order is best for letting us see relative popularity. But if there's a natural order, we'd normally want to use it.
--- 2.5 Exercise - Categorical variables ----------
Check "Exercises/2.5-exercise-categorical-variables_R_17.pdf"
Check "200-StatsBootCamp.R"
--- 2.6 Quiz - Categorical variables ----------
Question 1: Numeric variables are those like Age (in years) that we can think of as measurements. A categorical variable, like AgeDecade, defines groups that our entities belong to.
Question 2: Pie charts are very difficult to use if you want to assess group differences, unless there are only 2 groups. Stacked bar charts make comparisons between different groups difficult. Using percentages gives a clear impression of the order of the groups by size as well as giving a consistent indication of the fraction of all the entities that belong to that group. An ordinal variable is a set of groupings that has a natural order.Nominal variables contain groups that have no natural order and can often usefully be plotted in the order of their frequencies.
Question 3: Chart reading question
Question 4: Chart reading question

Week 02 -- 03262018 ------------------------------------------------------------
--- 2.7 Numeric variables ----------
I'll talk about centre
Plotting numeric variables shows us interesting characteristics of our data.
It's called a stacked dot plot. Each value is plotted against the scale using a dot-- so each dot represents a person.
Insight defaults from drawing dot plots to drawing histograms, like this one, at about 2,000 observations. Histograms are faster to draw for large data sets. But you'll see they're giving us the same shapes to interpret.
Here the main things we look for in dot plots-- centre, spread, shape, and oddities.
When the data is nearly symmetric, the mean and the median are almost the same.
This sort of shape is said to be skewed. With skewed data, there's no sharp notion of centre.
So which measure of centre should we use? That depends on what we want to use it for. For incomes, and many highly-skewed variables, the median tends to be preferable because it better represents the common experience, or what is typical. Half of the people get less. Half get more.
--- 2.8 Features of numeric variables ----------
Check "Articles/2.8-Features of Numeric Variables.pdf"
Centre: Median and Mean
Spread: Interquartile Range (IQR) and Standard deviation
Shape: Modality (unimodal, bimodal, trimodal) and Symmetry and skewness(symmetric, positively and negatively skewed)
Oddities: Outlier(s), Gaps and Clusters, Spike, Truncation, and Truncation with spike
Means can be quite badly affected by outliers in smaller data sets whereas medians are not.
Recall that if the shape is strongly skewed the mean and median can be quite different.
Standard Deviation and Variance: http://www.mathsisfun.com/data/standard-deviation.html
Positive skew = right skew = a longer right tail 
Negative skew = left skew = a longer left tail
How to Find the Median Value: http://www.mathsisfun.com/median.html
Quartiles: https://www.mathsisfun.com/data/quartiles.html
-- 2.9 Feature spotting ----------
I'll talk about spread, shape, and oddities (good graph examples--I should built them in R if we don't do it in next chapter)
We’ll introduce you to box plots and measures of spread, and to shape and oddities.
When we cut the data in half-- half above, half below-- this gives us the median. The position that divides the bottom half in half-- so that a quarter of the observations lie below, and three-quarters above it-- is the first, or lower, quartile. Similarly, the third, or upper, quartile divides the upper half of the data in half. So that three-quarters lies below, and a quarter of the observations lie above. Circling this gives us the middle half. Putting it together gives us the box plot.
The concept of spread answers the questions-- how spread out are the observations along the scale? Or equivalently, how much did these observations vary?
Boyfriend: https://xkcd.com/539/
--- 2.10 Exercise - Numeric variables ----------
Check "Exercises/2.10-exercise-numeric-variables_R_17.pdf"
Check "200-StatsBootCamp.R"
--- 2.11 Quiz - Numeric variables ----------
Question 1: The value where our stacked dot plot or histogram balances is the mean. The middle value of the data is the median. 
In statistics “Average” refers to the vague idea of “centre”. “Mean” and “Median” are precise, but different, ways of trying to implement the vague idea of “average”.
Question 2: FALSE:The mean for this data will be very different to the median, due to the shape of the dot plot.
The middle line of the box plot corresponds to the median BPDiaAve.
The dot plot and box plot is reasonably symmetric. The mean and median would be quite similar.
Question 3: FALSE: The median and mean of the number of drinks per day would be very similar.
The data is strongly positively skewed.
--- 2.12 Comparing groups ----------
The most useful insights from data come from spotting an important change.
Shifts vs. Background variability
The extent of a shift
shift and overlap
So high numbers of Children Per Woman seem to be associated with factors that tend to go along with poverty.
I just mean within-group variability. It would probably have been better to express it like that.
‘Shift’ is basically a change (move) in centres. ‘Background variability’ is the variability of values in each group around their centres.
--- 2.13 Exercise - Comparing groups ----------
Check "Exercises/2.13-exercise-comparing-groups_R_17.pdf"
Check "200-StatsBootCamp.R"
--- 2.14 Time travel ----------
Explore changes over time and find some interesting and consistent trends. Perform analyses using three variables at once.
--- 2.15 Exercise - Time travel ----------
Check "Exercises/2.15-exercise-time-travel_R_17.pdf"
Check "200-StatsBootCamp.R"
--- 2.16 Quiz - Comparing groups ----------
Question 1: TRUE: Europe & Central Asia has the biggest median.
This median is the furthest to the right.
TRUE: Every Region had at least one country with an ALE value over 75 years.
The individual values are the dots. There is at least one dot above 75 years within every Region.
TRUE: There is a lot of overlap in the data for all Regions except Sub Saharan Africa.
There is almost complete overlap between the sets of points for all Regions except Sub-Saharan Africa which is shifted substantially to the left and has at most half overlap with the other Regions.
FALSE: The spread (as summarised by the IQR) for Sub-Saharan Africa is much bigger than for East Asia & Pacific.
Sub-Saharan Africa’s IQR (box width) is similar if not smaller than that for East Asia & Pacific.
Question 2: TRUE: For each Region, the median ALE has been larger in recent years than it was in 1952.
The dot plots for all regions move to the right over the years showing a longer life expectancy.
TRUE: For most Regions, the increases in median ALE have been slowing down over recent years.
The shift from left to right (showing a lengthening of life expectancy) is in smaller increments between years than previously.
FALSE: The variability in ALE has reduced over time for all regions.
For example, the spread of the data for Sub-Saharan Africa has increased since the 1950s
--- 2.17 Questioning strategy in Quizzes and Tests ----------
Most of you are time-poor so we want make sure that every element of the course, including each quiz and test, is aimed at increasing learning.
--- 2.18 Assessment - Boot Camp ----------
I have no plans to upgrade
Just skip
--- 2.19 Weekly Reflections ----------
Over analyzing data is a trap for young players. Models are best if they are simple, but if you over-analyze the data your model will be very complicated and impossible to explain. It'll also be very hard to use. If you can see that the main relationships are simple, the insight you can get is far more useful for making informed decisions. Gotta be better than guessing!!


Week 03 -- 04062018 ------------------------------------------------------------
RELATIONSHIPS ------------------------------------------------------------------
--- 3.1 Introduction to relationships ----------
This week we will talk about relationships between categorical and numeric variables and how to read and interpret the graphs that reveal them.
Although we didn't use the 'r' word last week, we were already talking about relationships when we started investigating how family sizes have been affected by time and location. In statistical language we'd say "we investigated the relationships between the variable's fertility, year, and geographical region."
categorical variables: Dimensions
numeric variables: Measures
Why do people care about relationships between variables? Most of you will have heard of risk factors for diseases. The basic idea of risk factors is that certain variables can help tell us how much more or less likely it is that a person will get a disease.
We investigate relationships between variables to figure out what is going on and to help us describe what is happening in the real world. Also, to predict what will happen in the future, and to explain how things work, and to control or change real world outcomes.
We will start thinking in terms of a variable of primary interest whose behaviour we want to predict or explain (like getting cancer). We will call this our outcome variable. 
In answer to your question, outcome and response variable are both common names for the same thing -- Chris Wild
There are other variables that we think might be predictive of outcome variable behaviour. We will call these predictor variables.
This week I'll introduce you to the main concepts and tools for working with relationships. You will start using the American NHANES health data to look at social issues such as risky behaviour, socioeconomic status, and the effects of age and gender on testosterone. We'll also look at global issues like CO2 emissions and energy use using the Gapminder data.
--- 3.2 Relationships between categorical variables ----------
How to plot data on two categorical variables so that you can look for relationships between them.
Using the NHANES 2009-2012 data, we'll investigate how age group and gender predict educational achievement levels. Education is our outcome of interest. Age and gender are our predictor variables. First, using gender as a predictor, we want to see how the distribution of educational attainment differs between females and males. (min 1:00)
If there was no difference between the female and male distributions, we'd say there was no relationship between education and gender.
We'll now rearrange the sets of bars so that corresponding bars for females and males are placed beside one another. This is called a side-by-side bar chart. (vs. separate bar graphs)
A separate set of plots of the outcome variable, one for each predictor group, is good for revealing gross differences and overall shape. The side-by-side plot is good for looking at detailed differences.
--- 3.3 Week 3 glossary ----------
Check "Articles/1.13-data-to-inzight-glossary.pdf"
Cluster, No relationship, Outcome variable, Prediction, Predictor variable, Relationship, Scatterplot, Scatter, Side-by-side bar chart, Trend
--- 3.4 Changes across sub groups ----------
It is easy to see that the pattern of smokers being much more likely to say "Yes" to regular marijuana than non-smokers is remarkably consistent across both age, (down rows), and economic circumstances, (across columns).
--- 3.5 Exercise - Relationships between categorical variables ----------
Check "Exercises/3.05-exercise-relationships-between-categorical-variables_R_17.pdf"
--- 3.6 Quiz - Relationships between categorical variables ----------
Question 1: The variable of primary interest that we wish to be able to predict is known as the outcome variable. The variable, or variables that we use to try and achieve this is/are known as the predictor variable(s).
Question 2: When we are looking at relationships between categorical variables, we 1) can either use separate bar charts or side by side bar charts. 2) use separate bar charts to try and determine if there are differences in overall shape for the different groups that make up the predictor variable. 3) use side-by-side bar charts to highlight differences between corresponding categories.
FALSE: ..., we can only work with two categorical variables at a time.
If the overall shapes are the same, the predictor variable has no real effect.
When we detect differences in overall shape in the separate bar charts, side-by-side bar charts allow us to focus our attention on the individual group differences.
Questions 3: This statement is FALSE – we would expect the heights of the “yes” bars for each level of education to be the almost the same if this statement was true.
Question 4: This answer is FALSE - RegularMarij is the outcome variable. It is the distribution of RegularMarij that is being plotted each time. (Definition Trick - Yikes!)
--- 3.7 Relationships between numeric variables ----------
Hans Roslings' book Factfulness
We used scatter plots to display relationships between two numeric variables. We introduced interpreting scatter plots in terms of trend and scatter. We also saw examples with obvious clusters of points, triggering the question, "Why are these sets of individuals so different?" But usually, it is most useful to view scatter plots in terms of trend plus scatter with the occasional outlier.
--- 3.8 Trend, scatter and outliers ----------
We'll start by looking at a range of trend plus scatter, scatter plot behaviours.
Our outcome variable is the liver length and the predictor variable is the gestational age of the foetus, which is an estimate of the time since conception. (X:gestational age and Y:liver length)
But hang on a minute. When we look at the scatter, we see that there is a reasonable amount of variation and liver lengths of healthy 18-week old and a lot of variation in the liver lengths of normal 35-week olds. We clearly need to take that into account.
This simple example conveys many of the biggest ideas about the prediction problem, even though we've informally drawn the lines by eye.We can think of the trend here as a sort of summary of the strongest pattern in the data. This picture shows that where there is a lot of scatter or about the trend, we need to predict our outcome using a wide brackets of values. Where the scatter is small, our range of predicted values will be much narrower and probably more useful. Predictions from data can only work well if the data you have is representative of the way things behave in the setting in which you want to make the prediction
The trend summarises the main pattern we see in the data. This is a notion of averaging going on.
Projecting husband: https://xkcd.com/605/
--- 3.9 Exercise - Relationships between numeric variables ----------
Check "Exercises/3.09-exercise-relationships-between-numeric-variables_R_17.pdf"
When we call iNZightPlot(x,y) using two numeric variables x and y we will get a scatterplot. The 1st variable (x) gets plotted against the horizontal axis and the 2nd variable (y) is plotted against the vertical axis. So we should put the predictor variable first and the outcome variable second.
--- 3.10 Quiz - Relationships between numeric variables ----------
Question 1: When we have a trend in our scatter plot, the scatter around the trend tells us how strong a relationship is.
Question 2: When we do a scatterplot of two numeric variables, 1) the outcome variable is put on the vertical axis. 2) the predictor variable is put on the horizontal axis. 3) observations that are unusually far from the trend are called outliers and should be checked to determine if they are real values or mistakes. 4) if we see clusters of points, this suggests that there may be different groups of individuals present (e.g. males and females).
FALSE: ...variables, if there is a relationship between the predictor and outcome variables, the trend in the scatterplot will always be a straight line. (Trends may be curved lines.)
Question 3: For each value of number of children per woman it is the orange trend line that goes approximately through the centre of the data.
Question 4: United Arab Emirates is not an outlier as it is within the general envelope of points scattered around the trend line.
--- 3.11 Assessment - Relationships ----------
I have no plans to upgrade
Just skip
--- 3.12 Weekly Reflections ----------
Sometimes it is better not to know too much about the data - that way you tend to let the data speak rather than impose preconceived ideas on the data.


Week 04 -- 04132018 ------------------------------------------------------------
DEEPER INTO RELATIONSHIPS ------------------------------------------------------
--- 4.1 More relationships ----------
Hi all - This week we look deeper into relationships with scatterplots and some difficulties that can make it hard to easily see what is really happening. A few sneaky techniques can help us get the correct impression of the underlying relationship - Mike
Relationships between numeric & categorical variables
Relationships between categorical & categorical variables
Relationships between numeric & numeric variables
https://xkcd.com/833/
--- 4.2 Lines, curves and smoothers ----------
But so far, all our curves have been freehand curves, drawn by eye to make us really engage with seeing trends. This is important as the untrained eye can be misled.
Linear is used to capture a trend that looks like a straight line.
Quadratic curves could be used to capture trend-curve shapes that look like any segment of one of the two curves on the left.
Cubic curves are more flexible because they can take up to two bends. 
Smoothers are even more flexible and take on an even greater variety of shapes. You can control how flexible a smoother is using a slider.
The right-hand plot is what you get when you click the "Inference Information" button in iNZight. A set of curves like this is often described as a nest of curves.
Here's a small data set. Which of all these possible lines best captures the trend? First, we'll have to decide what we mean by best. Let's draw a candidate line. For every data point, there's a corresponding point on the line. This is the prediction this line would make for that data point. The predicted point and the real observation seldom coincide, leading to a set of prediction errors. These prediction errors are the vertical arrows on the plot. We want to choose the line that makes the smallest prediction errors in some overall average sense. 
Most software uses the least squares method, which minimises the sum of the squares of the prediction errors.
--- 4.3 Week 4 glossary ----------
Check "Articles/1.13-data-to-inzight-glossary.pdf"
Association, Colour gradient, Correlation, Cubic curves, Intercept, Jittering, Linear trend, Overprinting, Quadratic curves, Running quantiles, Slope, Smoother, Subsetting, Tile density plot, Transparency
--- 4.4 Interpreting the slope of a trend line ----------
Check "Articles/4.04-Interpreting the Slope of a Trend Line.pdf"
height = 85.68 + 5.76 ∗ age
y = m ∗ x + c
In our example, y is height, x is age and Get Summary gives you the values of m and c that produce the trend line on the graph.
The slope of the line is 5.76. What does this number mean?
The slope of a line is the change in y produced by a 1-unit increase in x.
For our example, the trend line would predict that if someone was 1-year older (x increases by 1), then they would be about 5.76cm taller (y increases by 5.76).
https://www.mathsisfun.com/
https://www.mathsisfun.com/data/straight_line_graph.html
https://www.mathsisfun.com/equation_of_line.html
https://www.mathsisfun.com/algebra/quadratic-equation-graph.html
--- 4.5 Association and correlation ----------
Statisticians say two variables are associated if there is a relationship between them that is too strong to be likely to arise simply by chance. Otherwise there is no association.
The association can be strong (very little scatter compared to the movement in the trend) or weak (lots of scatter around the trend).
An association is called positive if y tends to get bigger when x gets bigger and negative if y tends to get smaller as x gets bigger.
Correlation measures a specific form of association. It is a measure of how close the points are to lying on a straight line.
Correlations take values between -1 and +1. A correlation of +1 occurs when all of the points lie exactly on a line that has a positive slope. A correlation of -1 occurs when all of the points lie exactly on a line that has a negative slope. The correlation is zero if there is no relationship. 
As the relationship gets stronger, the correlation gets closer to either -1 or +1. As the relationship gets weaker, the correlation gets closer to zero.
When there is a strong relationship in a scatterplot, people tend to jump to a premature and often false conclusion that changes in the predictor are actually causing changes in the outcome. (Awesome examples: http://www.tylervigen.com/spurious-correlations)
Check "Articles/4.05-stats_causation_vs_correlation.pdf"
In theory, these are easy to distinguish — an action or occurrence can cause another (such as smoking causes lung cancer), or it can correlate with another (such as smoking is correlated with alcoholism). If one action causes another, then they are most certainly correlated. But just because two things occur together does not mean that one caused the other, even if it seems to make sense.
There are several reasons why common sense conclusions about cause and effect might be wrong.
This is why epidemiological (or observational) studies are so important. These are studies in which large groups of people are followed over time, and their behavior and outcome is also observed.
Without clear reasons to accept causality, we should only accept correlation. Two events occurring in close proximity does not imply that one caused the other, even if it seems to makes perfect sense.
http://www.istics.net/Correlations/
http://guessthecorrelation.com/
--- 4.6 Overcoming perceptual problems ----------
Overprinting vs. Jittering
Overprinting vs. Transparency
Jittering vs. Transparency
So we really do need aids like this to see properly into scatter plots for large data sets.
This helps us to see gaps between data points, usually caused by a rounding. The blood pressures here are all rounded to whole numbers. Using very small plotting symbols is good for seeing discreteness or separateness.
To summarise, using no transparency emphasises what's happening on the edges of the data, while high transparency lets us look at the comparative density of the observations in the bulk of the data.
--- 4.7 Exercise - Techniques for scatterplots ----------
Check "Exercises/4.07-exercise-techniques-for-scatterplots_R_17.pdf"
We can use transparency, running quartiles, and jittering to get a clearer picture of the density of the data.
--- 4.8 Quiz - Enhancing scatterplots ----------
Question 1: Comments for a weakly scattered graph
1) Make the points semi-transparent.
There are only a few small areas of the plot that have a lot of values overprinted. It is not a huge problem with this plot.
2) Colour the points by Age.
Colouring the points by Age would not give us any new information as Age is already a predictor variable.
3) Add a straight trend line.
The data appear curved so would be better to fit a trend line with a curve in it.
4) Decrease the size of the symbols.
Decreasing the size of the symbols may help to see separateness but is not the most useful technique for this plot.
5) Add a smoother and running quartiles. (Correct)
A smoother is designed to be flexible and fit the data in a variety of shapes. It will summarise the trend curve and other quantiles will add information about what is happening in the scatter.
Question 2: Jittering is a useful technique for seeing if there are a lot of values sitting directly on top of one another. We already know this with the use of transparency.
--- 4.9 Diving deeper with more variables ----------
More variables vs. Colour
More variables vs. Subsetting
In reality, we use colour to investigate the effect of a new variable.
We'll now move on to subsetting. We can see this with the set of plots or by playing through the plots like a movie.
For data exploration, it's not a matter of which is best. We often use both in the hopes of triggering insights.
--- 4.10 Our changing health and wealth ----------
Visualization tools: Jittering, Transparency, Size, Running quantiles, Colour, Subsetting
--- 4.11 Exercise - Advanced scatterplots for deeper analysis ----------
Check "Exercises/4.07-exercise-techniques-for-scatterplots_R_17.pdf"
--- 4.12 Diving deeper into relationships ----------
Question 1: There is a positive relationship between ChildrenPerWoman and InfantMortality. As ChildrenPerWoman increases, so does the rate of InfantMortality.
In recent years, the relationship between InfantMortality and ChildrenPerWoman has become stronger. Over time we are seeing less scatter around the trend.
Question 2: Sizing the symbols according to population total emphasises the countries with larger populations. The bigger shapes stand out.
--- 4.13 Assessment - Deeper into relationships ----------
I have no plans to upgrade
Just skip
--- 4.14 Weekly Reflections ----------
3-D plotting/ :D


Week 05 -- 04172018 ------------------------------------------------------------
WHY WHAT I SEE IS NEVER THE WAY IT REALLY IS -----------------------------------
--- 5.1 Why what I see is not quite the way it really is ----------
So far, we have simply been concentrating on exploring our data. We didn't pause to worry about the reliability or representativeness of the data we were analysing. Our priority was to give you an appreciation of the potential of data analysis.
There are statistical ways of assessing and allowing for uncertainties, the fuzziness.
We still want to see this, but what we end up looking at is more like this, a total distortion of reality. And we may never know that this has happened. The first law of data analysis is garbage in, garbage out. No amount of sophisticated data analysis can turn bad data into reliable conclusions.
We'll start the week by talking about how data gets to be bad. Then we will go on to problems and determining whether changes in a predictive factor actually cause a change in outcome. And we'll finish the week talking about random error, with a particular focus on sampling errors.
http://bigdata-madesimple.com/dilberts-20-funniest-cartoons-on-big-data/
https://place.fi.ncsu.edu/local/catalog/course.php?id=4&ref=1
--- 5.2 Bad data ----------
Armspan vs Height
The point is that there are a lot of strongly visible patterns in this plot that have nothing to do with the real world of human body shapes. They are artefacts, artificial patterns caused by deficiencies in the data collection process.
We know that there are a lot of things wrong with this data because we know a lot about arm spans, heights, and children. But if we were investigating something we knew almost nothing about, we'd probably have no idea that we were looking at artefacts, rather than facts, aspects of the real relationship.
Artefacts are artificial patterns caused by deficiencies in the data collection process. No data collection processes are ever perfect, so in data analysis we're always struggling to distinguish between facts and artefacts.
Bad measurement processes, measurements that do not actually measure what they are meant to, and bias, the process by which some things get recorded while others don't, can cause systematic biases.
Real data is also full of holes, values that are missing for various reasons. If the people we have values for tend to be different from those whose values have gone missing, then we automatically have bias.
The best protection against bad data is to design good data collection processes at the outset. That is before the data is collected.
https://www.statschat.org.nz/
--- 5.3 Week 5 glossary ----------
Check "Articles/1.13-data-to-inzight-glossary.pdf"
Artefacts, Biased selection processes, Causal conclusion, Cause, Causation, Confounder (Lurking variable, Confounding variable.), Measurement Error, Observational Study, Random Error, Random sampling, Randomised Experiment, Reliability, Representative, Sample size, Sampling error(s), Sampling variation, Selection processes, Systematic biases, Validity
--- 5.4 Measurement, validity and reliability ----------
You will often hear the names of two generic big ideas in measurement, however, “validity” and “reliability”. A measure is valid if it is “measuring the right thing”. It is reliable if, when you measure the same thing over and over again, you get pretty much the same answer.
Check "Articles/5.04-Measurement, validity and reliability.pdf"
Check "Articles/5.04-Chris Wild Paper.pdf"
https://www.dur.ac.uk/smart.centre/ by Professor Jim Ridgway
It is a brave (or foolhardy) person who believes that measures of any social phenomenon are stable over time.
http://www.pewforum.org/2015/04/02/religious-projections-2010-2050/
--- 5.4 Selection biases ----------
The selection-biases people tend to be most familiar with are the biases in polls and surveys from causes other than sampling (statisticians call them “non-sampling errors”) and those are what we will discuss here.
The biases that arise this way are referred to as self-selection bias. The people who do contribute are often very different from this who don’t and so are not representative of the general population.
“Scientific” polls and surveys with low response rates are likely to give biased results for the same basic reasons (there it’s called non-response bias).
Or in the words or images used in ancient maps, an alert that “here be dragons.”
https://www.youtube.com/watch?v=G0ZZJXw4MTA
In cases where it is a practical possibility, survey samplers would sample from a list of everybody in the population of interest (the target population).
The approximation has often been something like an electoral roll (lists of everyone eligible and registered to vote). Or they will sample by sampling from the available (landline) telephone numbers coupled with some strategy to choose a person in the house that had that number. This used to work really well but now the fraction of houses without landlines has become substantial. So the mismatch between the sampling frame and the population of interest – the population we want to project our findings to – is the source of frame errors.
Statistics only justifies an extrapolation of findings from the sample taken to the population that was actually sampled from.


Week 05 -- 04182018 ------------------------------------------------------------
--- 5.6 Data cleaning ----------
In large research projects, much more time may be spent on “cleaning” the data before analysis begins than on analysis itself.
Data collection processes seldom run entirely smoothly.
For example, if for Gender, we are using “Female” and “Male”, close variants such as “female”, “fem”, “F” and “f” would have to be converted to “Female”. Otherwise analysis programs treat them as entirely different categories.
--- 5.7 Quiz - Bad data ----------
Question 1:
Random selection helps avoid biased selection processes.
Receiving benefits encourages people to participate in the observation study. If the participation rate is not high, the results may not be representative as selected people who go to the trouble of participating are likely to be different in important ways from selected people who do not, thus undoing the good work that random selection has done.
Accepting volunteers is likely to cause bias in the data collection because volunteers are likely to be different in important ways from from people who don’t volunteer. In fact NHANES do not accept volunteers, only people who have been randomly selected.
Selecting the householder and using an interviewer to screen the participant helps to get a representative sample of the US population.
Medical Professionals will ensure that measurements are taken correctly and consistently giving much better data than if less highly-trained people had done this.
Participants will be more willing to answer questions and participate if they know that their personal information is secure. If they didn’t do this the participation rates would be lower and the results would be skewed towards people who don’t worry much about personal information and these may well be different in important ways from people who do care about the security of their personal information.
Question 2:
An artefact is an artificial pattern caused by deficiencies in the data collection process.
A variable that affects both the predictor and outcome variable is called a confounding variable or a lurking variable.
The best way to avoid artefacts is to design good data collection processes before the data is collected.
--- 5.8 Causation and Confounding, Part I ----------
There is always the chance that the real culprit is that the groups we are looking at are unbalanced with respect to some other important factor.
A variable is said to be a cause of changes in the outcome if actually changing its value leads to a change in the pattern of the outcomes.
A variable like age in our example is called a confounder, or lurking variable. Strictly, a confounder is something that causes changes in both the outcome and the predictor of interest. When we look at smoking in a naive way, as in the graph, its effects are all mixed up (confounded) with the effects of the confounder variable Age.
While an association between variables and observational data is not proof of anything, it is a clue that can be very helpful in ongoing detective work.
--- 5.9 Causation and Confounding, Part II ----------
In the context of categorical data, the problem we are looking at is called Simpson's paradox.
Statisticians have developed sophisticated ways of trying to accomplish the same thing for smaller data sets. Tools include matched sampling and regression modelling, but they all involve making some fairly strong assumptions.
--- 5.10 Quiz - Causes and lurking variables ----------
Question 1:
It is an observational study because the data has been observed and recorded in existing conditions in the world without intervention.
The difference in the number of people in the groups is not the problem. The important imbalance between the groups is that they do not contain people of comparable ages.
Question 2:
Observation studies can point to a possible cause of an effect but cannot reliably establish that something is a cause.
In an experiment, the experimenter enforces which experimental units receive the treatment. In an observational study, we simply compare units that happen to have received each of the treatments.


Week 05 -- 04202018 ------------------------------------------------------------
--- 5.11 Random error, Part I ----------
We looked at ways data can conspire to mislead us. We looked at problems caused by bad measurement systems and biased selection mechanisms. These are data quality issues. They result in the data we're looking at giving a distorted picture of the reality we're trying to understand.
Random error is a small data problem, by which I mean it's a problem in data sets that are not huge. 
With random sampling errors the bigger the sample we take, the smaller the errors we make. So where possible, we can reduce error by increasing the size of our sample.
The random error in a sample from a population depends on the sample size. The larger the sample size, the smaller the random error. Having a fixed percentage of the population would not help (as small populations would have smaller samples) and would also make some situations impossible to get samples from (e.g. a sample of people living in China)
--- 5.12 Random error, Part II ----------
Remember, in reality, we don't know the true value of the target. We only ever take one sample. And we can never know how big the sampling error is.
We can see that increasing the sample size reduces how big the sampling error can be. It suggests the following metaphor from photography. When random sampling error is the only source of error, increasing the sample size is like sharpening the focus.
I don't want to leave you thinking random sampling's terrible. Look at all the errors we get. Random sampling is still the best way we know of getting data that's not plagued by biases. Everything else tends to be much worse. And with random sampling, we can get a pretty good idea of how reliable our estimates are, whereas non-random selections tend to lead to unknown biases of unknown size.
Some take-home lessons-- all estimates are wrong. Bad estimates lead to bad decisions. An estimate is not particularly useful if we have no idea how wrong it could be. Sampling errors get smaller when we take bigger samples, whereas systematic biases don't.
--- 5.13 Exercise - Sampling variation - numeric data ----------
Check "Exercises/5.13-Explore-sampling-variation-numeric_vitonline16.pdf"
The median and lower quartile results seem to be 'quantised' with discrete values showing as shoulders. I wonder if it uses integer values for these instead of floating point which is used for average.
The data values are discrete (rounded to whole numbers) so the median must be either a whole number (n odd) or fall half way between 2 whole numbers (n even)
--- 5.14 Exercise - Sampling variation - proportions ----------
Check "Exercises/5.14 -Explore-sampling-variation-proportions_vitonline16.pdf"
Very nice visual presentation of population statistics (mean, median, proportions); statistics of random samples, their sampling distributions; effect of sample size and number of samples.
--- 5.15 Assessment - Why what I see is never the way it really is ----------
I have no plans to upgrade
Just skip
--- 5.16 Weekly Reflections ----------
It was to show how much variation and estimation error you get when you take samples from a population.


Week 06 -- 04242018 ------------------------------------------------------------
ESTIMATION WITH CONFIDENCE -----------------------------------------------------
--- 6.1 Introduction to estimation with confidence ----------
We'll learn how to put an interval around our estimates to allow for sampling error. These intervals are called confidence intervals.
Suppose my sample gave 46% for travelling by motor car. If I all I had was my sample value (46%), but I knew sample values in this situation had a margin of error of about 10%, I'd conclude that the true population value was somewhere between 36% and 56%. That's the basic idea behind what statisticians call a confidence interval, a range we're pretty sure covers the true value. It's a common sense way of thinking.
--- 6.2 Confidence Intervals from Bootstrap re-sampling ----------
The name was taken from a 19th century expression, "to pull yourself up by your bootstraps". This has come to mean getting out of a difficult situation by your own efforts. 
Bootstrap re-sampling in statistics began with a 1979 paper by the famous Stanford University statistician, Brad Efron. A bootstrap resample is generated by sampling from the sample (our data) with replacement.
We want it to be the same size as our data sample. And if we take several of these resamples, we want them to be different because we want to imitate sampling variation. If they were all identical, there would be no variation. (Bucket of 8 -- pick one --again bucket of 8 --pick one --so you may pick the same item again)
All I want you to take from these animations is re-sampling variation looks a lot like sampling variation. Skip to 6 minutes and 11 secondsOur take-home message is to use bootstrap re-sampling error, which we can see, to estimate the extent of sampling error, which we can't see. In other words, we use bootstrap re-sampling to answer the question, "How wrong could I be?"
--- 6.3 Week 6 glossary ----------
Check "Articles/1.13-data-to-inzight-glossary.pdf"
Bootstrap confidence interval, Bootstrap distribution, Bootstrap re-sampling, Comparison interval, Confidence Interval, Inference, Margin of error, Re-sampling, Statistical Inference
--- 6.4 Do Bootstrap Confidence Intervals work? ----------
Investigation: Computer simulation
--- 6.5 Exercise - Bootstrap re-sampling ----------
Check "Exercises/6.05-Bootstrap-re-sampling_16.pdf"
--- 6.6 Quiz - By one's own bootstraps ----------
Question 1: The Bootstrap re-samples should be of the same size as the original sample (and we sample with replacement).
Question 2: The circles in the re-sample plot are the individual values for one re-sample (red numbers) selected from the sample (black numbers on the left).
--- 6.7 Ways of obtaining Confidence Intervals ----------
Check "Articles/6.07-Ways of obtaining CIs_ARTICLE.pdf"
Methods for calculating confidence intervals come via two main routes:
mathematical theory obtained under idealised assumptions (e.g. normal distributions);
computer intensive methods of which the most generally useful is the bootstrap.
estimate ± 2 standard errors.
The “2 standard errors” is the margin of error.
This is the idea of robustness and we investigate robustness using computer simulations.
--- 6.8 Numeric outcomes ----------
Estimation with Confidence for a Numeric Outcome
--- 6.9 Confidence intervals for differences and visual approximations ----------
Check "Articles/6.09-2015_CIs for diffs & vis approx_ARTICLE.pdf"
In this article we address misconceptions about confidence intervals and iNZight’s comparison intervals.
--- 6.10 Categorical outcomes ----------
Estimation with Confidence for a Categorical Outcome
e can feel confident that we know fairly precisely where the true trends should be positioned at places where all the curves in the nest are very close together. We shouldn't have any confidence in the fitted trend in regions where the curves are far apart, because there, small changes in the data are making big changes in the result.
--- 6.11 Reading Confidence Intervals ----------
Check "Articles/6.10-Confidence Intervals_ARTICLE.pdf"
Group means with 95% Confidence Intervals 
ci.lower  estimate  ci.upper 
 16.5  16.9  17.4
Here the confidence interval extends from 16.5 (ci.lower) to 17.4 (ci.upper). How can we read, interpret and communicate these values?
We would typically say something like this:
“With 95% confidence, the population mean for age-of-first-use is somewhere between 16.5 and 17.4.”
The pattern used is:
“With 95% confidence, the population quantity for variable is somewhere between ci.lower and ci.upper .”
--- 6.12 Exercise - Inference with iNZight ----------
Check "Exercises/6.12-exercise-inference-with-inzight_R_17.pdf"
--- 6.13 Quiz - Spot the difference ----------
Question 1: If the comparison intervals overlap substantially, the true difference could go in either direction, or there might not be one at all. We simply don’t know.
Question 2: The comparison intervals on the pink and green bars on the right-hand side (hard-drugs=yes) are clearly separated. It is clear that those who have used marijuana regularly are much more likely to say they have used hard drugs than are those who have not used marijuana regularly.
--- 6.14 Assessment - Estimation with confidence ----------
I have no plans to upgrade
Just skip
--- 6.15 Weekly Reflections ----------


Week 07 -- 05092018 ------------------------------------------------------------
RANDOMISED EXPERIMENTS AND THE RANDOMISATION TEST ------------------------------
--- 7.1 Randomized experiments ----------
When media reports say something like, taking statins significantly reduces the risk of heart attack, what does the word "significant" mean?
Then we choose randomly who will be in each treatment group. Apply the treatments, observe the outcomes, and compare the groups.
This random assignment tends to balance the groups on everything except the treatment they're receiving, so that when we compare treatment groups, we are comparing like with like so that we are conducting a fair test.
A better design would be first to divide subjects up into age groups. Statisticians would call this "blocking on age." Second, they'd randomise "smoke" or "don't smoke" within an age group (or block) and then make the comparisons between smokers and non-smokers within the same block (groups of children of similar age).
--- 7.2 Fair tests ----------
Check "Articles/7.02-Fair Testing.pdf"
We haven’t talked about the special case of comparing one or more treatments to not being treated at all (“no treatment”) using a control group. Statistically, “no treatment” is just another treatment condition. 
You may have heard of the placebo effect (there can be surprisingly large changes in an outcome variable just from people knowing they are being treated for something). Control conditions need to allow for the placebo effect.
--- 7.3 Randomisation variation ----------
Random assignment of experimental units to treatment groups is the most reliable way people know for constructing fair tests of treatments. But it is by no means perfect. We’ll show you how varied the differences between groups can be simply due to random labelling.
Randomisation variation is the variability in the difference between the two “group” means produced by random allocation to “groups” (random labelling with group labels) and nothing else.
As with sampling, every time we multiply the number of points by four, we halve the amount of randomisation variation.
--- 7.4 Week 7 glossary ----------
Check "Articles/1.13-data-to-inzight-glossary.pdf"
Effect size, Experiment, Non-significant, p-value, Practically significant, Randomisation Test, Randomisation variation, Re-randomisation distribution, Re-randomisation, Significance, Significance test, Statistically significant, Tail proportions, Treatment, Treatment group, Type-1 error rate
--- 7.5 Quiz - Randomisation variation ----------
Question 1: Treatment groups are balanced when they are similar on all factors other than treatment, not just a single factor (age here).
Question 2: Randomisation variation is the variability in the difference between the two “group” means produced by random allocation to “groups” (random labelling with group labels) and nothing else.
--- 7.6 Randomisation test ----------
Randomisation variation motivates a type of test we do to try to determine whether the effects we've seen in a randomised experiment demonstrate real treatment differences, or whether they could just be "the luck of the draw".
Take randomized treatment group and re-randomise
We'll ask for the tail proportion to see how rare this is. It tells us that the luck of the draw gave us 15.92 or bigger, 10 times out of 1,000. That's 1% of the time. Put another way, random reassignment almost always gave us values smaller than this. 99% of the time they were smaller.
Conventionally, people start concluding something real has probably happened if the tail proportion is about 5% or smaller.
--- 7.7 Exercise - Using VIT to run a randomisation test ----------
Check "Exercises/7.07-Using-vit-to-run-a-randomisation.pdf"
--- 7.8 Quiz - Randomisation test ----------
Question 1: A single re-randomisation 
Question 2: Random re-assignment almost always gave us values smaller than our observed difference of 67 million.
--- 7.9 Percentages and multiple groups ----------
We're going to look at data from an experiment to compare the effectiveness of drug treatments for addiction to cocaine. 72 addicts were randomised to three treatment groups: Placebo(a dummy treatment) Lithium or Desipramine.
We see that only 4 of the 24 people on the Placebo treatment were cocaine-free. (That's about 17%.) The rest relapsed and used cocaine again. Six of those on Lithium were cocaine-free (that's 25%) whereas nearly 60% of those on Desipramine remained cocaine-free. On the face of it, Desipramine looks very effective compared to Lithium or Placebo.
--- 7.10 Exercise - Using VIT to run a randomisation test for proportions ----------
Check "Exercises/7.10-using-vit-to-run-a-randomisation-test-for-proportions.pdf"
--- 7.11 Statistical tests ----------
Check "Articles/7.11-Statistical Tests.pdf"
The randomisation tests you have seen and been using are a special case of what is known as statistical significance tests, or statistical hypothesis tests. (The situations we have worked with correspond to testing the hypothesis that “there are no true differences between the effects of the treatments”.)
The tail proportions we have been working with correspond to the p-values of significance testing theory (there is a complication about “sided-ness” that we will deal with at the end of this article).
In experimental situations a large p-value (large tail proportion) means that the luck of the randomisation quite often produces group differences as large or even larger than what we’ve got in our data. In this case the data provides no evidence that there are true treatment-group differences.
A small p-value means that the luck of the randomisation draw hardly ever produces group differences as large as we’ve got in our data. They are almost always smaller. In this case the data does provide evidence that there are true treatment-group differences.
Furthermore, the smaller the p-value, the stronger the evidence that true treatment differences exist.
When should we start to claim “evidence” of true differences? It is quite common practice to start claiming evidence of true differences if the p-value is 5% or smaller. At that point the result is commonly said to be ”statistically significant” .
https://simplystatistics.org/2013/12/16/a-summary-of-the-evidence-that-most-published-research-is-false/
https://xkcd.com/882/
--- 7.12 Out of the Fog and into Power ----------
The power of a study is the probability that it would detect an effect exists when the true effect was of a nominated size.
It's like this: a helicopter pilot might say, "If a building's 100 metres high or higher, I want to know that there's a building there. If it's shorter than that, I'm OK with not knowing." So as part of designing a study, we have to specify a minimum effect size at which we'd want to know that a true effect exists. We then ensure that the study uses enough experimental subjects so that if the true state of the world was our specified effect size or larger, we would almost certainly conclude that a treatment difference existed.
--- 7.13 Assessment - Randomised experiments ----------
I have no plans to upgrade
Just skip
--- 7.14 Weekly Reflections ----------


Week 08 -- 05092018 ------------------------------------------------------------
TIME SERIES --------------------------------------------------------------------
--- 8.1 Introducing Time Series Data ----------
We'll look at data collected over time where we're interested in looking at changes over time. Statisticians call it "Time-series data". This is a standalone module that can be studied at any time after Week Four. People are often fascinated by time series data because it can help them understand the past but, even more, to help them predict the future.
There's a basic pattern that repeats every year. We call such patterns, seasonal patterns.
Why do people worry about identifying and estimating patterns, like the ones we've been seeing? Mainly because they want to take them and project them into the future. They want to use them for forecasting what's going to happen next so that they can plan for this anticipated future, how to adapt to it or take advantage of it.
https://www.bloomberg.com/graphics/2015-whats-warming-the-world/
https://public.tableau.com/en-us/s/gallery/evolution-global-temperature?utm_source=feedburner&utm_medium=email&utm_campaign=Feed%3A+VizOfTheDay+%28Viz+of+the+Day+-+Beautiful+Visual+Stories%29
https://xkcd.com/1732/
--- 8.2 Time series data ----------
Check "Articles/8.02-Time Series data.pdf"
If there are holes it will report an error (or may possibly produce silly results).
If you have some holes in your series you could fill them in with guesses at the sort of values that might have been likely if a reading was able to be taken, and then change these guesses and see how that affects the results (“sensitivity analysis”) - or find someone who knows about more sophisticated techniques and more sophisticated software. Holes are very common, for example, with data recorded daily on week days (Monday-Friday) because of public holidays.
--- 8.3 Seasonal decomposition and forecasting, part I ----------
How big is the seasonal effect?
Zero is the no-change value because adding zero makes no change
For this series, the residuals are small compared to the movement of the trend (which ranges from about 40,000 to 60,000) and the seasonal swings (which go between about plus or minus 20,000). Now this is what's called an "additive decomposition". It assumes the underlying seasonal swings are the same every year and they add to the trend value, as we've seen. They're only useful if the seasonal swings look similar. Next, we'll show an example where the seasonal swings are obviously not constant. This will lead us to another type of decomposition, "multiplicative decomposition".
--- 8.4 Seasonal decomposition and forecasting, part II ----------
Note the horizontal line at zero on the additive plot. Adding zero makes no change. Whereas the horizontal line on the multiplicative plot is at one. In a multiplicative world, one is the no-adjustment value because multiplying by one makes no change.
Here's the forecast for the next two years for Australia. It is projected forward to the trend and the seasonal swings giving the red lines. It's also put confidence bands (in pink) around the forecast.
The text window gives the numerical values. It's all been done using a statistical technique called the Holt-Winters method. The details are complicated and involve several levels of smoothing. Holt-Winters is the only forecasting method implemented in iNZight.
Holt-Winters is a good general purpose forecasting method, when the trend is basically monotone (which means it's either rising or it's falling, but it's not doing both).
--- 8.5 Week 8 glossary ----------
Check "Articles/1.13-data-to-inzight-glossary.pdf"
Additive decomposition, Confidence bands, Decomposition plot, Forecast, Holt-Winters method, Multiplicative decomposition, Quarterly data, Residuals, Seasonal patterns, Seasonal series, Time-series data
--- 8.6 Exercise - Time Series for a single variable ----------
Check "Exercises/8.06-Time-series-for-a-single-variable.pdf"
--- 8.7 Quiz - Single series ----------
Question 1: Seasonality refers to a pattern that repeats over a regular or fixed time period. This time period does not have to be a year. It is often also a week or even a day.
Question 2:
--- 8.8 Forecasting ----------
Check "Articles/8.08-Forecasting.pdf"
Forecasts are predictions but the word “forecast” is more common in connection with time-series data.
https://www.otexts.org/fpp/1
--- 8.9 Comparing series ----------
 A complementary way of displaying the information gives each country its own graphs. Now we can see the trends for each country much more easily and compare the trends. But to tell anything about relative sizes we have to rely on the scales.
--- 8.10 Exercise - Time Series analysis for more than one series ----------
Check "Exercises/8.10-Time-series-analysis-for-more-than-one-series.pdf"
--- 8.11 Assessment - Time series ----------
I have no plans to upgrade
Just skip
--- 8.12 Full glossary ----------
Check "Articles/1.13-data-to-inzight-glossary.pdf"
--- 8.13 Life after the course ----------
Farewell (or, in Māori, Haere rā)


