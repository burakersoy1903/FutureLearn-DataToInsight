Week 01 -- 03232018 ------------------------------------------------------------
Introduction -------------------------------------------------------------------
--- 1.1 Course introduction ----------
Chris quote: "Diving into data"
iNZight -- https://www.stat.auckland.ac.nz/~wild/iNZight/index.php
--- 1.2 About this course ----------
You create visual representations of data, usually in the iNZight software.
Discussion about specified topics, such as possible interpretations of statistical data.
Lead educator, Chris Wild, (https://www.stat.auckland.ac.nz/~wild) (@ChrisWild)
Educator, Tracey Meek,
Educator, Mike Forster, (@MikeForster)
Technology mentor, Tom Elliott.(http://tomelliott.co.nz)(inzight_support@auckland.ac.nz)
--- 1.3 How to use FutureLearn ----------
Follow teachers
--- 1.4 Welcome - please introduce yourself ----------
Howdy, y'all! This is Burak Ersoy. I live in Texas, USA; however, I am from Turkey originally. I work as a business clinical analyst at a children's hospital and I hold a MSc. in Computer Science. With that being said, I am not new in data analytics or technology, but I am new in R and medical statistics. I am very excited to see examples with health data and ready to learn new approaches through this Data to Insight challenge. Thank you!
--- 1.5 How do we use data analysis? ----------
So statistics lets us give an air of objectivity rather than just an opinion.
Even hospitals make clever use of data to cut costs and to keep patients moving through the system. We used data analysis to help the heart unit at Auckland City Hospital fix a bottleneck in their system. This bottleneck was causing nearly 30% of elective heart surgeries to be cancelled at the very last minute. And this wasn't just costly for the hospital, but was also very, very stressful for patients and their families. So we built a model of the patient flow through the intensive-care unit. And we fed into this model all kinds of data: the data of the arrival times of patients, the kind of treatment they needed, how long they spent in the unit. And then also staff rosters and the schedules for elective surgery. And then we used this model to simulate all kinds of "what if?" scenarios-- a whole range of them-- to see what the best way would be to reduce cancellations. The hospital then made some changes and the cancellation rate fell from nearly 30% to 10%.
--- 1.6 The place of data analysis in problem solving ----------
Check "Images/ppdac.png"
The PPDAC model: Problem, Plan, Data, Analysis, Conclusions
A knowledge-based solution to the real problem requires better understanding of how some things work.
“whipping it into shape” (data cleaning)
The Problem step is about trying to turn these vague feelings into much more precise goals, some very specific questions that should be able to be answered using data.
The formation of conclusions typically involves the analyst and a subject-matter expert (e.g. someone who understands the business) who will “own” the conclusions.
This article has been about purpose-collected data.
Check "Articles/1.6-Statistical Thinking in Empirical Enquiry.pdf" --Original PPDAC model article
Check "Articles/1.6-Place of data analysis in problem solving.pdf"
--- 1.7 Datasets for Data to Insight ----------
“Garbage in, Garbage out” is a standard catch-phrase in information-technology and it certainly applies to statistical data analysis today.
The main datasets for this course are NHANES and Gapminder.
NHANES: National Health and Nutrition Examination Survey (https://www.cdc.gov/nchs/nhanes/index.htm)
Gapminder: (https://www.gapminder.org/) (https://www.gapminder.org/data/)
Check "Articles/1.7-gapminder-dataset-overview.pdf"
Check "Articles/1.7-NHANES 2009_2012.pdf"
Datasets in csv format (https://www.stat.auckland.ac.nz/~wild/data/FutureLearn/)
Datasets in tab-delimited text format (https://www.stat.auckland.ac.nz/~wild/data/FutureLearn_TabTxt/)
Also available in Datasets folder
--- 1.8 Data visualisation ----------
The Joy of Stats: (https://www.gapminder.org/videos/the-joy-of-stats/)
--- 1.9 Introduction to iNZight and iNZight Lite  ----------
To gain insights into the real world using data you need to produce graphs and summaries using statistical data-analysis software.
--- 1.10 Exercise - Install iNZight ----------
Check "Exercises/1.10-exercise-install-R_17.pdf"
Check "100-InstallTheRPackages.R"
iNZight Lite: (http://lite.docker.stat.auckland.ac.nz/)
iNZight GitHub: (https://github.com/iNZightVIT)
iNZight User Guides: (https://www.stat.auckland.ac.nz/~wild/iNZight/user_guides/)
package ‘rematch’ successfully unpacked and MD5 sums checked
package ‘rlang’ successfully unpacked and MD5 sums checked
package ‘hms’ successfully unpacked and MD5 sums checked
package ‘cellranger’ successfully unpacked and MD5 sums checked
package ‘tidyselect’ successfully unpacked and MD5 sums checked
package ‘objectSignals’ successfully unpacked and MD5 sums checked
package ‘gtools’ successfully unpacked and MD5 sums checked
package ‘memoise’ successfully unpacked and MD5 sums checked
package ‘readr’ successfully unpacked and MD5 sums checked
package ‘readxl’ successfully unpacked and MD5 sums checked
package ‘forcats’ successfully unpacked and MD5 sums checked
package ‘tidyr’ successfully unpacked and MD5 sums checked
package ‘SparseM’ successfully unpacked and MD5 sums checked
package ‘MatrixModels’ successfully unpacked and MD5 sums checked
package ‘FNN’ successfully unpacked and MD5 sums checked
package ‘gridExtra’ successfully unpacked and MD5 sums checked
package ‘XML’ successfully unpacked and MD5 sums checked
package ‘objectProperties’ successfully unpacked and MD5 sums checked
package ‘RGtk2’ successfully unpacked and MD5 sums checked
package ‘gWidgets2’ successfully unpacked and MD5 sums checked
package ‘cairoDevice’ successfully unpacked and MD5 sums checked
package ‘gdata’ successfully unpacked and MD5 sums checked
package ‘gWidgets2RGtk2’ successfully unpacked and MD5 sums checked
package ‘s20x’ successfully unpacked and MD5 sums checked
package ‘survey’ successfully unpacked and MD5 sums checked
package ‘quantreg’ successfully unpacked and MD5 sums checked
package ‘hexbin’ successfully unpacked and MD5 sums checked
package ‘hextri’ successfully unpacked and MD5 sums checked
package ‘viridis’ successfully unpacked and MD5 sums checked
package ‘gridSVG’ successfully unpacked and MD5 sums checked
--- 1.11 Using iNZight Lite ----------
iNZight Lite is a web-application that runs over the internet and does not need to be installed. It will run on tablets. The user interface for iNZight Lite is rather different from that for iNZight.
--- 1.12 Data organisation ----------
[Comments] I guess in databases, entities are represented in a form of tables during implementation as you said but during design they are referred to as entities in the Entity-Relationship Diagram or Objects if you are using Object-Oriented approach.
Rows and Cells vs. Entities vs Variables (statistical term)
Column header
Data Organisation Format: Rectangular data
Gaps in the data
Missing Value: NULL or NA in iNZight
Different programmes have different default missing-value code conventions.
Numeric Variables vs Categorical Variables (defining groups)
--- 1.13 Week 1 glossary ----------
Check "Articles/1.13-data-to-inzight-glossary.pdf"
Categorical variable, Entities, Frequency, Missing value code, Missing value, Numeric variable, Rectangular data, Variable
--- 1.14 Using your own data ----------
Some general data preparation rules (10 items)
10. Remove units from data, e.g. 5 years/5 yrs/5yr should all be just 5 and $10 is just 10
--- 1.15 Exercise - Load data into iNZight ----------
Check "Exercises/1.15-exercise-import-data-into-R_17.pdf"
Check "100-InstallTheRPackages.R"
--- 1.16 Quiz - Data Organisation ----------
Question 1: We arrange our data in a rectangular format where the entities (or individuals) data is being recorded for correspond to the rowsand the variables (or properties being recorded for those entities) correspond to the columns.
Question 2: We collect and analyse data so we can get insight into a problem of interest, make informed decisions rather than guess, and understand what could happen.
Question 3: The missing value in the red dotted circle should be recorded as a 0 or a space. This statement is FALSE – We should represent a missing value using a special code (e.g. NA for iNZight) or the cell should be entirely empty.
Question 4: AgeDecade is a numeric variable. This statement is FALSE – AgeDecade is a categorical variable because age has been divided up into age groups.
--- 1.17 Weekly Reflections ----------
Nice comments! :D
First week done!


Week 02 -- 03242018 ------------------------------------------------------------
STATS BOOT CAMP ----------------------------------------------------------------
--- 2.1 Introduction ----------
NHANES (in-hayns) survey data
We'll look at variables like Education, Marital Status, and Body Mass Index.
--- 2.2 Categorical variables ----------
Whenever I get a new data set, I try to familiarise myself with what I've got before I do any real analysis. I look for things that might surprise me and might indicate errors in the data. One of the first things I do is to look at each variable in turn.
Numeric variables are those we can think of as measurements, like Age and Weight here. Categorical variables, like Gender, Age Decade, Race3, Education, and Marital Status give us group membership labels.
A categorical variable like Marital Status divides our people up into categories or groups.
In 2011, NHANES changed their race categories to separate out Asian. It had previously been included in "Other". The name of the new variable is Race3.
Pies and stacked bars have the advantages of conveying the sense of being parts of a whole. However, they're not good for discovery because they're not good at letting you see changes and differences. And spotting changes is the lifeblood of discovery.
We get useful impressions of what the data are saying much more quickly from the graph than from a table of numbers. We look first at the graph to get an impression of what's happening, and then consult the table if we want more accuracy.
--- 2.3 Week 2 glossary ----------
Check "Articles/1.13-data-to-inzight-glossary.pdf"
Alpha-numeric, Background Variability, Bar chart, Bimodal, Box Plot, Centre, Dot plot, Frequency, Histogram, Interquartile range (IQR), Lower quartile, Mean, Median, Multiplicative, Nominal variable, Oddities, Ordinal variable, Outlier(s), Overlap, Pie chart, Quartiles, Relative Frequency, Shape, Skewed, Spread, Stacked bar chart, Subset, Symmetrical, Upper quartile, Variability
--- 2.4 Ordering categories ----------
If the categories have a natural ordering, the variable is said to be ordinal.
If there's no natural ordering, the variable is said to be nominal.
If there's no particular reason for setting categories in some other order, ordering them by height order is usually the most informative. We call this ordering by frequency.
Frequency is just another name for a count. 
o wrap up, we have the following ways of ordering. Alphabetic order helps us to locate a particular item in a list just as we do with a name in a phone book. Frequency order is best for letting us see relative popularity. But if there's a natural order, we'd normally want to use it.
--- 2.5 Exercise - Categorical variables ----------
Check "Exercises/2.5-exercise-categorical-variables_R_17.pdf"
Check "200-StatsBootCamp.R"
--- 2.6 Quiz - Categorical variables ----------
Question 1: Numeric variables are those like Age (in years) that we can think of as measurements. A categorical variable, like AgeDecade, defines groups that our entities belong to.
Question 2: Pie charts are very difficult to use if you want to assess group differences, unless there are only 2 groups. Stacked bar charts make comparisons between different groups difficult. Using percentages gives a clear impression of the order of the groups by size as well as giving a consistent indication of the fraction of all the entities that belong to that group. An ordinal variable is a set of groupings that has a natural order.Nominal variables contain groups that have no natural order and can often usefully be plotted in the order of their frequencies.
Question 3: Chart reading question
Question 4: Chart reading question

Week 02 -- 03262018 ------------------------------------------------------------
--- 2.7 Numeric variables ----------
I'll talk about centre
Plotting numeric variables shows us interesting characteristics of our data.
It's called a stacked dot plot. Each value is plotted against the scale using a dot-- so each dot represents a person.
Insight defaults from drawing dot plots to drawing histograms, like this one, at about 2,000 observations. Histograms are faster to draw for large data sets. But you'll see they're giving us the same shapes to interpret.
Here the main things we look for in dot plots-- centre, spread, shape, and oddities.
When the data is nearly symmetric, the mean and the median are almost the same.
This sort of shape is said to be skewed. With skewed data, there's no sharp notion of centre.
So which measure of centre should we use? That depends on what we want to use it for. For incomes, and many highly-skewed variables, the median tends to be preferable because it better represents the common experience, or what is typical. Half of the people get less. Half get more.
--- 2.8 Features of numeric variables ----------
Check "Articles/2.7-Features of Numeric Variables.pdf"
Centre: Median and Mean
Spread: Interquartile Range (IQR) and Standard deviation
Shape: Modality (unimodal, bimodal, trimodal) and Symmetry and skewness(symmetric, positively and negatively skewed)
Oddities: Outlier(s), Gaps and Clusters, Spike, Truncation, and Truncation with spike
Means can be quite badly affected by outliers in smaller data sets whereas medians are not.
Recall that if the shape is strongly skewed the mean and median can be quite different.
Standard Deviation and Variance: http://www.mathsisfun.com/data/standard-deviation.html
Positive skew = right skew = a longer right tail 
Negative skew = left skew = a longer left tail
How to Find the Median Value: http://www.mathsisfun.com/median.html
Quartiles: https://www.mathsisfun.com/data/quartiles.html
-- 2.9 Feature spotting ----------
I'll talk about spread, shape, and oddities (good graph examples--I should built them in R if we don't do it in next chapter)
We’ll introduce you to box plots and measures of spread, and to shape and oddities.
When we cut the data in half-- half above, half below-- this gives us the median. The position that divides the bottom half in half-- so that a quarter of the observations lie below, and three-quarters above it-- is the first, or lower, quartile. Similarly, the third, or upper, quartile divides the upper half of the data in half. So that three-quarters lies below, and a quarter of the observations lie above. Circling this gives us the middle half. Putting it together gives us the box plot.
The concept of spread answers the questions-- how spread out are the observations along the scale? Or equivalently, how much did these observations vary?
Boyfriend: https://xkcd.com/539/
--- 2.10 Exercise - Numeric variables ----------
Check "Exercises/2.10-exercise-numeric-variables_R_17.pdf"
Check "200-StatsBootCamp.R"
--- 2.11 Quiz - Numeric variables ----------
Question 1: The value where our stacked dot plot or histogram balances is the mean. The middle value of the data is the median. 
In statistics “Average” refers to the vague idea of “centre”. “Mean” and “Median” are precise, but different, ways of trying to implement the vague idea of “average”.
Question 2: FALSE:The mean for this data will be very different to the median, due to the shape of the dot plot.
The middle line of the box plot corresponds to the median BPDiaAve.
The dot plot and box plot is reasonably symmetric. The mean and median would be quite similar.
Question 3: FALSE: The median and mean of the number of drinks per day would be very similar.
The data is strongly positively skewed.
--- 2.12 Comparing groups ----------
The most useful insights from data come from spotting an important change.
Shifts vs. Background variability
The extent of a shift
shift and overlap
So high numbers of Children Per Woman seem to be associated with factors that tend to go along with poverty.
I just mean within-group variability. It would probably have been better to express it like that.
‘Shift’ is basically a change (move) in centres. ‘Background variability’ is the variability of values in each group around their centres.
--- 2.13 Exercise - Comparing groups ----------
Check "Exercises/2.13-exercise-comparing-groups_R_17.pdf"
Check "200-StatsBootCamp.R"
--- 2.14 Time travel ----------
Explore changes over time and find some interesting and consistent trends. Perform analyses using three variables at once.
--- 2.15 Exercise - Time travel ----------
Check "Exercises/2.15-exercise-time-travel_R_17.pdf"
Check "200-StatsBootCamp.R"
--- 2.16 Quiz - Comparing groups ----------
Question 1: TRUE: Europe & Central Asia has the biggest median.
This median is the furthest to the right.
TRUE: Every Region had at least one country with an ALE value over 75 years.
The individual values are the dots. There is at least one dot above 75 years within every Region.
TRUE: There is a lot of overlap in the data for all Regions except Sub Saharan Africa.
There is almost complete overlap between the sets of points for all Regions except Sub-Saharan Africa which is shifted substantially to the left and has at most half overlap with the other Regions.
FALSE: The spread (as summarised by the IQR) for Sub-Saharan Africa is much bigger than for East Asia & Pacific.
Sub-Saharan Africa’s IQR (box width) is similar if not smaller than that for East Asia & Pacific.
Question 2: TRUE: For each Region, the median ALE has been larger in recent years than it was in 1952.
The dot plots for all regions move to the right over the years showing a longer life expectancy.
TRUE: For most Regions, the increases in median ALE have been slowing down over recent years.
The shift from left to right (showing a lengthening of life expectancy) is in smaller increments between years than previously.
FALSE: The variability in ALE has reduced over time for all regions.
For example, the spread of the data for Sub-Saharan Africa has increased since the 1950s
--- 2.17 Questioning strategy in Quizzes and Tests ----------
Most of you are time-poor so we want make sure that every element of the course, including each quiz and test, is aimed at increasing learning.
--- 2.18 Assessment - Boot Camp ----------
I have no plans to upgrade
Just skip
--- 2.19 Weekly Reflections ----------
Over analyzing data is a trap for young players. Models are best if they are simple, but if you over-analyze the data your model will be very complicated and impossible to explain. It'll also be very hard to use. If you can see that the main relationships are simple, the insight you can get is far more useful for making informed decisions. Gotta be better than guessing!!


Week 03 -- 04062018 ------------------------------------------------------------
RELATIONSHIPS ------------------------------------------------------------------
--- 3.1 Introduction to relationships ----------
This week we will talk about relationships between categorical and numeric variables and how to read and interpret the graphs that reveal them.
Although we didn't use the 'r' word last week, we were already talking about relationships when we started investigating how family sizes have been affected by time and location. In statistical language we'd say "we investigated the relationships between the variable's fertility, year, and geographical region."
categorical variables: Dimensions
numeric variables: Measures
Why do people care about relationships between variables? Most of you will have heard of risk factors for diseases. The basic idea of risk factors is that certain variables can help tell us how much more or less likely it is that a person will get a disease.
We investigate relationships between variables to figure out what is going on and to help us describe what is happening in the real world. Also, to predict what will happen in the future, and to explain how things work, and to control or change real world outcomes.
We will start thinking in terms of a variable of primary interest whose behaviour we want to predict or explain (like getting cancer). We will call this our outcome variable. 
In answer to your question, outcome and response variable are both common names for the same thing -- Chris Wild
There are other variables that we think might be predictive of outcome variable behaviour. We will call these predictor variables.
This week I'll introduce you to the main concepts and tools for working with relationships. You will start using the American NHANES health data to look at social issues such as risky behaviour, socioeconomic status, and the effects of age and gender on testosterone. We'll also look at global issues like CO2 emissions and energy use using the Gapminder data.
--- 3.2 Relationships between categorical variables ----------
How to plot data on two categorical variables so that you can look for relationships between them.
Using the NHANES 2009-2012 data, we'll investigate how age group and gender predict educational achievement levels. Education is our outcome of interest. Age and gender are our predictor variables. First, using gender as a predictor, we want to see how the distribution of educational attainment differs between females and males. (min 1:00)
If there was no difference between the female and male distributions, we'd say there was no relationship between education and gender.
We'll now rearrange the sets of bars so that corresponding bars for females and males are placed beside one another. This is called a side-by-side bar chart. (vs. separate bar graphs)
A separate set of plots of the outcome variable, one for each predictor group, is good for revealing gross differences and overall shape. The side-by-side plot is good for looking at detailed differences.
--- 3.3 Week 3 glossary ----------
Check "Articles/1.13-data-to-inzight-glossary.pdf"
Cluster, No relationship, Outcome variable, Prediction, Predictor variable, Relationship, Scatterplot, Scatter, Side-by-side bar chart, Trend
--- 3.4 Changes across sub groups ----------
It is easy to see that the pattern of smokers being much more likely to say "Yes" to regular marijuana than non-smokers is remarkably consistent across both age, (down rows), and economic circumstances, (across columns).
--- 3.5 Exercise - Relationships between categorical variables ----------
Check "Exercises/3.05-exercise-relationships-between-categorical-variables_R_17.pdf"
--- 3.6 Quiz - Relationships between categorical variables ----------
Question 1: The variable of primary interest that we wish to be able to predict is known as the outcome variable. The variable, or variables that we use to try and achieve this is/are known as the predictor variable(s).
Question 2: When we are looking at relationships between categorical variables, we 1) can either use separate bar charts or side by side bar charts. 2) use separate bar charts to try and determine if there are differences in overall shape for the different groups that make up the predictor variable. 3) use side-by-side bar charts to highlight differences between corresponding categories.
FALSE: ..., we can only work with two categorical variables at a time.
If the overall shapes are the same, the predictor variable has no real effect.
When we detect differences in overall shape in the separate bar charts, side-by-side bar charts allow us to focus our attention on the individual group differences.
Questions 3: This statement is FALSE – we would expect the heights of the “yes” bars for each level of education to be the almost the same if this statement was true.
Question 4: This answer is FALSE - RegularMarij is the outcome variable. It is the distribution of RegularMarij that is being plotted each time. (Definition Trick - Yikes!)
--- 3.7 Relationships between numeric variables ----------
Hans Roslings' book Factfulness
We used scatter plots to display relationships between two numeric variables. We introduced interpreting scatter plots in terms of trend and scatter. We also saw examples with obvious clusters of points, triggering the question, "Why are these sets of individuals so different?" But usually, it is most useful to view scatter plots in terms of trend plus scatter with the occasional outlier.
--- 3.8 Trend, scatter and outliers ----------
We'll start by looking at a range of trend plus scatter, scatter plot behaviours.
Our outcome variable is the liver length and the predictor variable is the gestational age of the foetus, which is an estimate of the time since conception. (X:gestational age and Y:liver length)
But hang on a minute. When we look at the scatter, we see that there is a reasonable amount of variation and liver lengths of healthy 18-week old and a lot of variation in the liver lengths of normal 35-week olds. We clearly need to take that into account.
This simple example conveys many of the biggest ideas about the prediction problem, even though we've informally drawn the lines by eye.We can think of the trend here as a sort of summary of the strongest pattern in the data. This picture shows that where there is a lot of scatter or about the trend, we need to predict our outcome using a wide brackets of values. Where the scatter is small, our range of predicted values will be much narrower and probably more useful. Predictions from data can only work well if the data you have is representative of the way things behave in the setting in which you want to make the prediction
The trend summarises the main pattern we see in the data. This is a notion of averaging going on.
Projecting husband: https://xkcd.com/605/
--- 3.9 Exercise - Relationships between numeric variables ----------
Check "Exercises/3.09-exercise-relationships-between-numeric-variables_R_17.pdf"
When we call iNZightPlot(x,y) using two numeric variables x and y we will get a scatterplot. The 1st variable (x) gets plotted against the horizontal axis and the 2nd variable (y) is plotted against the vertical axis. So we should put the predictor variable first and the outcome variable second.
--- 3.10 Quiz - Relationships between numeric variables ----------
Question 1: When we have a trend in our scatter plot, the scatter around the trend tells us how strong a relationship is.
Question 2: When we do a scatterplot of two numeric variables, 1) the outcome variable is put on the vertical axis. 2) the predictor variable is put on the horizontal axis. 3) observations that are unusually far from the trend are called outliers and should be checked to determine if they are real values or mistakes. 4) if we see clusters of points, this suggests that there may be different groups of individuals present (e.g. males and females).
FALSE: ...variables, if there is a relationship between the predictor and outcome variables, the trend in the scatterplot will always be a straight line. (Trends may be curved lines.)
Question 3: For each value of number of children per woman it is the orange trend line that goes approximately through the centre of the data.
Question 4: United Arab Emirates is not an outlier as it is within the general envelope of points scattered around the trend line.
--- 3.11 Assessment - Relationships ----------
I have no plans to upgrade
Just skip
--- 3.12 Weekly Reflections ----------
Sometimes it is better not to know too much about the data - that way you tend to let the data speak rather than impose preconceived ideas on the data.


Week 04 -- 04132018 ------------------------------------------------------------
DEEPER INTO RELATIONSHIPS ------------------------------------------------------
--- 4.1 More relationships ----------
Hi all - This week we look deeper into relationships with scatterplots and some difficulties that can make it hard to easily see what is really happening. A few sneaky techniques can help us get the correct impression of the underlying relationship - Mike
Relationships between numeric & categorical variables
Relationships between categorical & categorical variables
Relationships between numeric & numeric variables
https://xkcd.com/833/
--- 4.2 Lines, curves and smoothers ----------
But so far, all our curves have been freehand curves, drawn by eye to make us really engage with seeing trends. This is important as the untrained eye can be misled.
Linear is used to capture a trend that looks like a straight line.
Quadratic curves could be used to capture trend-curve shapes that look like any segment of one of the two curves on the left.
Cubic curves are more flexible because they can take up to two bends. 
Smoothers are even more flexible and take on an even greater variety of shapes. You can control how flexible a smoother is using a slider.
The right-hand plot is what you get when you click the "Inference Information" button in iNZight. A set of curves like this is often described as a nest of curves.
Here's a small data set. Which of all these possible lines best captures the trend? First, we'll have to decide what we mean by best. Let's draw a candidate line. For every data point, there's a corresponding point on the line. This is the prediction this line would make for that data point. The predicted point and the real observation seldom coincide, leading to a set of prediction errors. These prediction errors are the vertical arrows on the plot. We want to choose the line that makes the smallest prediction errors in some overall average sense. 
Most software uses the least squares method, which minimises the sum of the squares of the prediction errors.
--- 4.3 Week 4 glossary ----------
Check "Articles/1.13-data-to-inzight-glossary.pdf"
Association, Colour gradient, Correlation, Cubic curves, Intercept, Jittering, Linear trend, Overprinting, Quadratic curves, Running quantiles, Slope, Smoother, Subsetting, Tile density plot, Transparency
--- 4.4 Interpreting the slope of a trend line ----------
Check "Articles/4.04-Interpreting the Slope of a Trend Line.pdf"
height = 85.68 + 5.76 ∗ age
y = m ∗ x + c
In our example, y is height, x is age and Get Summary gives you the values of m and c that produce the trend line on the graph.
The slope of the line is 5.76. What does this number mean?
The slope of a line is the change in y produced by a 1-unit increase in x.
For our example, the trend line would predict that if someone was 1-year older (x increases by 1), then they would be about 5.76cm taller (y increases by 5.76).
https://www.mathsisfun.com/
https://www.mathsisfun.com/data/straight_line_graph.html
https://www.mathsisfun.com/equation_of_line.html
https://www.mathsisfun.com/algebra/quadratic-equation-graph.html
--- 4.5 Association and correlation ----------
Statisticians say two variables are associated if there is a relationship between them that is too strong to be likely to arise simply by chance. Otherwise there is no association.
The association can be strong (very little scatter compared to the movement in the trend) or weak (lots of scatter around the trend).
An association is called positive if y tends to get bigger when x gets bigger and negative if y tends to get smaller as x gets bigger.
Correlation measures a specific form of association. It is a measure of how close the points are to lying on a straight line.
Correlations take values between -1 and +1. A correlation of +1 occurs when all of the points lie exactly on a line that has a positive slope. A correlation of -1 occurs when all of the points lie exactly on a line that has a negative slope. The correlation is zero if there is no relationship. 
As the relationship gets stronger, the correlation gets closer to either -1 or +1. As the relationship gets weaker, the correlation gets closer to zero.
When there is a strong relationship in a scatterplot, people tend to jump to a premature and often false conclusion that changes in the predictor are actually causing changes in the outcome. (Awesome examples: http://www.tylervigen.com/spurious-correlations)
Check "Articles/4.05-stats_causation_vs_correlation.pdf"
In theory, these are easy to distinguish — an action or occurrence can cause another (such as smoking causes lung cancer), or it can correlate with another (such as smoking is correlated with alcoholism). If one action causes another, then they are most certainly correlated. But just because two things occur together does not mean that one caused the other, even if it seems to make sense.
There are several reasons why common sense conclusions about cause and effect might be wrong.
This is why epidemiological (or observational) studies are so important. These are studies in which large groups of people are followed over time, and their behavior and outcome is also observed.
Without clear reasons to accept causality, we should only accept correlation. Two events occurring in close proximity does not imply that one caused the other, even if it seems to makes perfect sense.
http://www.istics.net/Correlations/
http://guessthecorrelation.com/
--- 4.6 Overcoming perceptual problems ----------
Overprinting vs. Jittering
Overprinting vs. Transparency
Jittering vs. Transparency
Check "Book/4.06-Overcoming-perceptual-problems-illustrated.pdf"
So we really do need aids like this to see properly into scatter plots for large data sets.
This helps us to see gaps between data points, usually caused by a rounding. The blood pressures here are all rounded to whole numbers. Using very small plotting symbols is good for seeing discreteness or separateness.
To summarise, using no transparency emphasises what's happening on the edges of the data, while high transparency lets us look at the comparative density of the observations in the bulk of the data.
--- 4.7 Exercise - Techniques for scatterplots ----------
Check "Exercises/4.07-exercise-techniques-for-scatterplots_R_17.pdf"
We can use transparency, running quartiles, and jittering to get a clearer picture of the density of the data.
--- 4.8 Quiz -Enhancing scatterplots ----------
Question 1: Comments for a weakly scattered graph
1) Make the points semi-transparent.
There are only a few small areas of the plot that have a lot of values overprinted. It is not a huge problem with this plot.
2) Colour the points by Age.
Colouring the points by Age would not give us any new information as Age is already a predictor variable.
3) Add a straight trend line.
The data appear curved so would be better to fit a trend line with a curve in it.
4) Decrease the size of the symbols.
Decreasing the size of the symbols may help to see separateness but is not the most useful technique for this plot.
5) Add a smoother and running quartiles. (Correct)
A smoother is designed to be flexible and fit the data in a variety of shapes. It will summarise the trend curve and other quantiles will add information about what is happening in the scatter.
Question 2: Jittering is a useful technique for seeing if there are a lot of values sitting directly on top of one another. We already know this with the use of transparency.
--- 4.9 Diving deeper with more variables ----------
More variables vs. Colour
More variables vs. Subsetting
In reality, we use colour to investigate the effect of a new variable.
We'll now move on to subsetting. We can see this with the set of plots or by playing through the plots like a movie.
For data exploration, it's not a matter of which is best. We often use both in the hopes of triggering insights.
--- 4.10 Our changing health and wealth ----------
Visualization tools: Jittering, Transparency, Size, Running quantiles, Colour, Subsetting
--- 4.11 Exercise - Advanced scatterplots for deeper analysis ----------
Check "Exercises/4.07-exercise-techniques-for-scatterplots_R_17.pdf"
--- 4.12 Diving deeper into relationships ----------
Question 1: There is a positive relationship between ChildrenPerWoman and InfantMortality. As ChildrenPerWoman increases, so does the rate of InfantMortality.
In recent years, the relationship between InfantMortality and ChildrenPerWoman has become stronger. Over time we are seeing less scatter around the trend.
Question 2: Sizing the symbols according to population total emphasises the countries with larger populations. The bigger shapes stand out.
--- 4.13 Assessment - Deeper into relationships ----------
I have no plans to upgrade
Just skip
--- 4.14 Weekly Reflections ----------
3-D plotting/ :D


Week 05 -- 04172018 ------------------------------------------------------------
WHY WHAT I SEE IS NEVER THE WAY IT REALLY IS -----------------------------------
--- 5.1 Why what I see is not quite the way it really is ----------
So far, we have simply been concentrating on exploring our data. We didn't pause to worry about the reliability or representativeness of the data we were analysing. Our priority was to give you an appreciation of the potential of data analysis.
There are statistical ways of assessing and allowing for uncertainties, the fuzziness.
We still want to see this, but what we end up looking at is more like this, a total distortion of reality. And we may never know that this has happened. The first law of data analysis is garbage in, garbage out. No amount of sophisticated data analysis can turn bad data into reliable conclusions.
We'll start the week by talking about how data gets to be bad. Then we will go on to problems and determining whether changes in a predictive factor actually cause a change in outcome. And we'll finish the week talking about random error, with a particular focus on sampling errors.
http://bigdata-madesimple.com/dilberts-20-funniest-cartoons-on-big-data/
https://place.fi.ncsu.edu/local/catalog/course.php?id=4&ref=1
--- 5.2 Bad data ----------
Armspan vs Height
The point is that there are a lot of strongly visible patterns in this plot that have nothing to do with the real world of human body shapes. They are artefacts, artificial patterns caused by deficiencies in the data collection process.
We know that there are a lot of things wrong with this data because we know a lot about arm spans, heights, and children. But if we were investigating something we knew almost nothing about, we'd probably have no idea that we were looking at artefacts, rather than facts, aspects of the real relationship.
Artefacts are artificial patterns caused by deficiencies in the data collection process. No data collection processes are ever perfect, so in data analysis we're always struggling to distinguish between facts and artefacts.
Bad measurement processes, measurements that do not actually measure what they are meant to, and bias, the process by which some things get recorded while others don't, can cause systematic biases.
Real data is also full of holes, values that are missing for various reasons. If the people we have values for tend to be different from those whose values have gone missing, then we automatically have bias.
The best protection against bad data is to design good data collection processes at the outset. That is before the data is collected.
https://www.statschat.org.nz/
--- 5.3 Week 5 glossary ----------
Check "Articles/1.13-data-to-inzight-glossary.pdf"
Artefacts, Biased selection processes, Causal conclusion, Cause, Causation, Confounder (Lurking variable, Confounding variable.), Measurement Error, Observational Study, Random Error, Random sampling, Randomised Experiment, Reliability, Representative, Sample size, Sampling error(s), Sampling variation, Selection processes, Systematic biases, Validity
--- 5.4 Measurement, validity and reliability ----------
You will often hear the names of two generic big ideas in measurement, however, “validity” and “reliability”. A measure is valid if it is “measuring the right thing”. It is reliable if, when you measure the same thing over and over again, you get pretty much the same answer.
Check "Articles/5.04-Measurement, validity and reliability.pdf"
Check "Articles/5.04-Chris Wild Paper.pdf"
https://www.dur.ac.uk/smart.centre/ by Professor Jim Ridgway
It is a brave (or foolhardy) person who believes that measures of any social phenomenon are stable over time.
http://www.pewforum.org/2015/04/02/religious-projections-2010-2050/
--- 5.4 Selection biases ----------
The selection-biases people tend to be most familiar with are the biases in polls and surveys from causes other than sampling (statisticians call them “non-sampling errors”) and those are what we will discuss here.
The biases that arise this way are referred to as self-selection bias. The people who do contribute are often very different from this who don’t and so are not representative of the general population.
“Scientific” polls and surveys with low response rates are likely to give biased results for the same basic reasons (there it’s called non-response bias).
Or in the words or images used in ancient maps, an alert that “here be dragons.”
https://www.youtube.com/watch?v=G0ZZJXw4MTA
In cases where it is a practical possibility, survey samplers would sample from a list of everybody in the population of interest (the target population).
The approximation has often been something like an electoral roll (lists of everyone eligible and registered to vote). Or they will sample by sampling from the available (landline) telephone numbers coupled with some strategy to choose a person in the house that had that number. This used to work really well but now the fraction of houses without landlines has become substantial. So the mismatch between the sampling frame and the population of interest – the population we want to project our findings to – is the source of frame errors.
Statistics only justifies an extrapolation of findings from the sample taken to the population that was actually sampled from.


Week 05 -- MMDD2018 ------------------------------------------------------------
--- 5.6 Data cleaning ----------



